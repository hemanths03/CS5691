{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , VotingClassifier , GradientBoostingClassifier , AdaBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:14:05.945624Z","iopub.execute_input":"2021-11-10T17:14:05.946014Z","iopub.status.idle":"2021-11-10T17:14:05.957139Z","shell.execute_reply.started":"2021-11-10T17:14:05.945970Z","shell.execute_reply":"2021-11-10T17:14:05.956301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_1 = pd.read_csv(\"../input/datacontest1/Dataset_1_Training.csv\")\ntest_data_1 = pd.read_csv(\"../input/datacontest1/Dataset_1_Testing.csv\")\ntrain_data_2 = pd.read_csv(\"../input/datacontest1/Dataset_2_Training.csv\")\ntest_data_2 = pd.read_csv(\"../input/datacontest1/Dataset_2_Training.csv\")\n# Read co1 and co2\nco1 = train_data_1.tail()[-2:-1]\nco2 = train_data_1.tail()[-1:]\n\n# Remove the labels for co1, co2\nco1.pop('ID_REF')\nco2.pop('ID_REF')\n\n# convert co1, co2 into arrays\nco1 = np.array(co1)\nco2 = np.array(co2)\n\n# Transpose the data set with rows as training numbers\ntrain_data_1 = train_data_1[:-2]\ntrain_data_1 = train_data_1.T\n\ntest_data_1 = test_data_1.T\n\n# Make the first row of dataframe as columns\ntrain_data_1.columns = train_data_1.iloc[0]\ntrain_data_1 = train_data_1[1:]\n\ntest_data_1.columns = test_data_1.iloc[0]\ntest_data_1 = test_data_1[1:]\n\n# Read co3, co4, co5 and c06\nco3 = train_data_2.tail()[-4:-3]\nco4 = train_data_2.tail()[-3:-2]\nco5 = train_data_2.tail()[-2:-1]\nco6 = train_data_2.tail()[-1:]\n\n# Remove the labels for co3, co4, co5 and co6\nco3.pop('ID_REF')\nco4.pop('ID_REF')\nco5.pop('ID_REF')\nco6.pop('ID_REF')\n\n# convert co3, co4, co5 and co6 into arrays\nco3 = np.array(co3)\nco4 = np.array(co4)\nco5 = np.array(co5)\nco6 = np.array(co6)\n\n# Transpose the data set with rows as training numbers\ntrain_data_2 = train_data_2[:-4]\ntrain_data_2 = train_data_2.T\n\ntest_data_2 = test_data_2.T\n\n# Make the first row of dataframe as columns\ntrain_data_2.columns = train_data_2.iloc[0]\ntrain_data_2 = train_data_2[1:]\n\ntest_data_2.columns = test_data_2.iloc[0]\ntest_data_2 = test_data_2[1:]","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:14:12.527791Z","iopub.execute_input":"2021-11-10T17:14:12.528110Z","iopub.status.idle":"2021-11-10T17:14:33.913820Z","shell.execute_reply.started":"2021-11-10T17:14:12.528050Z","shell.execute_reply":"2021-11-10T17:14:33.912989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ds1_train, X_ds1_test, co1_train, co1_test = train_test_split(train_data_1, co1[0], test_size=0.2, random_state=10)\nX_ds1_train, X_ds1_test, co2_train, co2_test = train_test_split(train_data_1, co2[0], test_size=0.2, random_state=10)\nX_ds2_train, X_ds2_test, co3_train, co3_test = train_test_split(train_data_2, co3[0], test_size=0.2, random_state=10)\nX_ds2_train, X_ds2_test, co4_train, co4_test = train_test_split(train_data_2, co4[0], test_size=0.2, random_state=10)\nX_ds2_train, X_ds2_test, co5_train, co5_test = train_test_split(train_data_2, co5[0], test_size=0.2, random_state=10)\nX_ds2_train, X_ds2_test, co6_train, co6_test = train_test_split(train_data_2, co6[0], test_size=0.2, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:14:39.176191Z","iopub.execute_input":"2021-11-10T17:14:39.176891Z","iopub.status.idle":"2021-11-10T17:14:42.669362Z","shell.execute_reply.started":"2021-11-10T17:14:39.176836Z","shell.execute_reply":"2021-11-10T17:14:42.668693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert from integer to float\nX_ds1_train_fl = X_ds1_train.astype(float, 64)\nX_ds1_test_fl = X_ds1_test.astype(float, 64)\ntest_data_1_f1 = test_data_1.astype(float, 64)\n\n# Applying the same scaling to both the training and test data\nscalar = StandardScaler()\nX_ds1_train_scl = scalar.fit_transform(X_ds1_train_fl)\nX_ds1_test_scl = scalar.transform(X_ds1_test_fl)\ntest_data_1_scl = scalar.transform(test_data_1_f1)\n\n# Convert from integer to float\nX_ds2_train_fl = X_ds2_train.astype(float, 64)\nX_ds2_test_fl = X_ds2_test.astype(float, 64)\ntest_data_2_f1 = test_data_2.astype(float, 64)\n\n# Applying the same scaling to both the training and test data\nscalar = StandardScaler()\nX_ds2_train_scl = scalar.fit_transform(X_ds2_train_fl)\nX_ds2_test_scl = scalar.transform(X_ds2_test_fl)\ntest_data_2_scl = scalar.transform(test_data_2_f1)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:14:47.424943Z","iopub.execute_input":"2021-11-10T17:14:47.425607Z","iopub.status.idle":"2021-11-10T17:14:54.750476Z","shell.execute_reply.started":"2021-11-10T17:14:47.425566Z","shell.execute_reply":"2021-11-10T17:14:54.749442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA()\npca.fit_transform(X_ds1_train_scl)\n\ntotal = sum(pca.explained_variance_)\nk = 0\ncurrent_variance = 0\nwhile current_variance/total < 0.90:\n    current_variance += pca.explained_variance_[k]\n    k = k + 1\n    \nprint(k, \" features explain around 90% of the variance. From 22283 features to \", k, \", not too bad.\", sep='')\n\npca = PCA(n_components=k)\nX_ds1_train.pca = pca.fit(X_ds1_train_scl)\nX_ds1_train_pca = pca.transform(X_ds1_train_scl)\nX_ds1_test_pca = pca.transform(X_ds1_test_scl)\ntest_data_1_pca = pca.transform(test_data_1_scl)\n\nvar_exp = pca.explained_variance_ratio_.cumsum()\nvar_exp = var_exp*100\nplt.bar(range(k), var_exp);","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:00.030675Z","iopub.execute_input":"2021-11-10T16:31:00.030983Z","iopub.status.idle":"2021-11-10T16:31:01.303127Z","shell.execute_reply.started":"2021-11-10T16:31:00.030938Z","shell.execute_reply":"2021-11-10T16:31:01.302527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply PCA on training data\npca = PCA()\npca.fit_transform(X_ds2_train_scl)\n\ntotal = sum(pca.explained_variance_)\nk = 0\ncurrent_variance = 0\nwhile current_variance/total < 0.90:\n    current_variance += pca.explained_variance_[k]\n    k = k + 1\n    \nprint(k, \" features explain around 90% of the variance. From 54675 features to \", k, \", not too bad.\", sep='')\n\npca = PCA(n_components=k)\nX_ds2_train.pca = pca.fit(X_ds2_train_scl)\nX_ds2_train_pca = pca.transform(X_ds2_train_scl)\nX_ds2_test_pca = pca.transform(X_ds2_test_scl)\ntest_data_2_pca = pca.transform(test_data_2_scl)\n\nvar_exp = pca.explained_variance_ratio_.cumsum()\nvar_exp = var_exp*100\nplt.bar(range(k), var_exp);","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:03.165706Z","iopub.execute_input":"2021-11-10T16:31:03.16617Z","iopub.status.idle":"2021-11-10T16:31:11.014811Z","shell.execute_reply.started":"2021-11-10T16:31:03.166136Z","shell.execute_reply":"2021-11-10T16:31:11.014011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setSeed():\n    np.random.seed(0)\nsetSeed()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:13.058185Z","iopub.execute_input":"2021-11-10T16:31:13.058449Z","iopub.status.idle":"2021-11-10T16:31:13.06287Z","shell.execute_reply.started":"2021-11-10T16:31:13.058423Z","shell.execute_reply":"2021-11-10T16:31:13.062004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAdaBoostClassifierModellr(X_train, X_test, y_train, y_test):\n    setSeed()\n    abc_param_grid = {\n         'n_estimators': [10,20,30],\n    }\n    \n    abc_estimator = AdaBoostClassifier(base_estimator=LogisticRegression(random_state=0),random_state=0)\n    \n    adaBoost_model = GridSearchCV(abc_estimator, abc_param_grid, cv=3, scoring='accuracy')\n\n    # Train Adaboost Classifer\n    adaBoost_model = adaBoost_model.fit(X_train, y_train)\n    \n    print(\"Best Parameters:\\n\", adaBoost_model.best_params_)\n\n    #Predict the response for test dataset\n    y_pred = adaBoost_model.predict(X_test)\n\n    accuracy = round(accuracy_score(y_test, y_pred), 3)\n    print('AdaBoostClassifier model accuracy:', accuracy)\n    \n    cm_rf = confusion_matrix(y_test, y_pred)\n\n    ax = plt.subplot()\n    sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels') \n    ax.set_title('AdaBoost classifier Confusion Matrix') \n    labels = [0, 1]\n    ax.xaxis.set_ticklabels(labels) \n    ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return adaBoost_model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:20.466141Z","iopub.execute_input":"2021-11-10T16:31:20.466889Z","iopub.status.idle":"2021-11-10T16:31:20.473924Z","shell.execute_reply.started":"2021-11-10T16:31:20.46685Z","shell.execute_reply":"2021-11-10T16:31:20.473192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co3_model_9, _ = getAdaBoostClassifierModellr(X_ds2_train_pca, X_ds2_test_pca, co3_train, co3_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:23.408882Z","iopub.execute_input":"2021-11-10T16:31:23.409436Z","iopub.status.idle":"2021-11-10T16:31:24.017466Z","shell.execute_reply.started":"2021-11-10T16:31:23.409398Z","shell.execute_reply":"2021-11-10T16:31:24.016184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co3_ds1_pred = co3_model_9.predict(test_data_2_pca)\nco3_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:11:00.079384Z","iopub.execute_input":"2021-11-10T13:11:00.080148Z","iopub.status.idle":"2021-11-10T13:11:00.097007Z","shell.execute_reply.started":"2021-11-10T13:11:00.080107Z","shell.execute_reply":"2021-11-10T13:11:00.096148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getLogisticRegressionModel(X_train, X_test, y_train, y_test, plotConfusionMatrix=True):\n    setSeed()\n    log_grid = {'C': [1e-03, 1e-2, 1e-1, 1, 10], \n                     'penalty': ['l1', 'l2']}\n\n    log_estimator = LogisticRegression(solver='liblinear', random_state=0)\n    \n    log_model = GridSearchCV(estimator=log_estimator, \n                      param_grid=log_grid, \n                      cv=3,\n                      scoring = 'accuracy')\n\n    log_model.fit(X_train, y_train)\n\n    print(\"Best Parameters:\\n\", log_model.best_params_)\n\n    # Select best log model\n    best_log = log_model.best_estimator_\n\n    # Make predictions using the optimised parameters\n    log_pred = best_log.predict(X_test)\n    accuracy = round(accuracy_score(y_test, log_pred), 3)\n    print('Logistic Regression accuracy:', accuracy)\n\n    if plotConfusionMatrix:\n        cm_log =  confusion_matrix(y_test, log_pred)\n\n        ax = plt.subplot()\n        sns.heatmap(cm_log, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n        # labels, title and ticks\n        ax.set_xlabel('Predicted labels')\n        ax.set_ylabel('True labels') \n        ax.set_title('Logistic Regression Confusion Matrix') \n        labels = [0, 1]\n        ax.xaxis.set_ticklabels(labels) \n        ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return best_log, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:34.826392Z","iopub.execute_input":"2021-11-10T16:31:34.827062Z","iopub.status.idle":"2021-11-10T16:31:34.836084Z","shell.execute_reply.started":"2021-11-10T16:31:34.827025Z","shell.execute_reply":"2021-11-10T16:31:34.835181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getSVMModel(X_train_pca, X_test_pca, y_train, y_test, plotConfusionMatrix=True):\n    setSeed()\n    \n    # Parameter grid\n    svm_param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10], \"kernel\": [\"linear\", \"rbf\", \"poly\"], \"decision_function_shape\" : [\"ovo\", \"ovr\"]} \n\n    # Create SVM grid search classifier\n    svm_grid = GridSearchCV(SVC(random_state=0), svm_param_grid, cv=3)\n\n    # Train the classifier\n    svm_grid.fit(X_train_pca, y_train)\n\n    print(\"Best Parameters:\\n\", svm_grid.best_params_)\n\n    # Select best svc\n    best_svc = svm_grid.best_estimator_\n\n    # Make predictions using the optimised parameters\n    svm_pred = best_svc.predict(X_test_pca)\n    accuracy = round(accuracy_score(y_test, svm_pred), 3)\n    print('SVM accuracy:', accuracy)\n\n    if plotConfusionMatrix:\n        cm_svm =  confusion_matrix(y_test, svm_pred)\n\n        ax = plt.subplot()\n        sns.heatmap(cm_svm, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n        # Labels, title and ticks\n        ax.set_xlabel('Predicted labels')\n        ax.set_ylabel('True labels') \n        ax.set_title('SVM Confusion Matrix') \n        labels = [0, 1]\n        ax.xaxis.set_ticklabels(labels) \n        ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return best_svc, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:37.604137Z","iopub.execute_input":"2021-11-10T16:31:37.604596Z","iopub.status.idle":"2021-11-10T16:31:37.613693Z","shell.execute_reply.started":"2021-11-10T16:31:37.604553Z","shell.execute_reply":"2021-11-10T16:31:37.612495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rfModel(X_train, X_test, y_train, y_test, plotConfusionMatrix=True):\n    setSeed()\n    rf_param_grid = {\n         'bootstrap': [True, False],\n#          'max_depth': [10, 20, 30],\n#          'min_samples_leaf': [1, 2, 4],\n#          'min_samples_split': [2, 5, 10],\n         'min_samples_leaf': [8, 10, 12, 14],\n         'min_samples_split': [3, 5, 7],\n         'n_estimators': [50, 80, 100],\n    }\n    \n    # Instantiate random forest classifier\n    rf_estimator = RandomForestClassifier(random_state=0)\n    \n    # Create the GridSearchCV object\n    rf_model = GridSearchCV(estimator=rf_estimator, param_grid=rf_param_grid, cv=3, scoring='accuracy')\n    \n    # Fine-tune the hyperparameters\n    rf_model.fit(X_train, y_train)\n    \n    print(\"Best Parameters:\\n\", rf_model.best_params_)\n    \n    # Get the best model\n    rf_model_best = rf_model.best_estimator_\n\n    # Make predictions using the optimised parameters\n    rf_pred = rf_model_best.predict(X_test)\n    \n    accuracy = round(accuracy_score(y_test, rf_pred), 3)\n    print('Random Forest accuracy:', accuracy)\n\n    if plotConfusionMatrix:\n        cm_rf = confusion_matrix(y_test, rf_pred)\n\n        ax = plt.subplot()\n        sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n        # labels, title and ticks\n        ax.set_xlabel('Predicted labels')\n        ax.set_ylabel('True labels') \n        ax.set_title('Random Forest Confusion Matrix') \n        labels = [0, 1]\n        ax.xaxis.set_ticklabels(labels) \n        ax.yaxis.set_ticklabels(labels, rotation=360);\n\n    return rf_model_best, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:40.067434Z","iopub.execute_input":"2021-11-10T16:31:40.067691Z","iopub.status.idle":"2021-11-10T16:31:40.075716Z","shell.execute_reply.started":"2021-11-10T16:31:40.067656Z","shell.execute_reply":"2021-11-10T16:31:40.075168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def votingModel(X_train, X_test, y_train, y_test):\n    \n    # Select best logistic regression model\n    best_log, _ = getLogisticRegressionModel(X_train, X_test, y_train, y_test, plotConfusionMatrix=False)\n\n    # Select best svc\n    best_svc, _ = getSVMModel(X_train, X_test, y_train, y_test, plotConfusionMatrix=False)\n    \n    # Select best rf\n    best_rf, _ = rfModel(X_train, X_test, y_train, y_test, plotConfusionMatrix=False)\n    \n    # group / ensemble of models\n    estimator = []\n    estimator.append(('LR', best_log))\n    estimator.append(('SVC', best_svc))\n    estimator.append(('NBC', best_rf))\n\n    # Voting Classifier with hard voting\n    setSeed()\n    vot_Model = VotingClassifier(estimators = estimator, voting ='hard')\n    vot_Model.fit(X_train, y_train)\n    y_pred = vot_Model.predict(X_test)\n\n    accuracy = round(accuracy_score(y_test, y_pred), 3)\n    print('Voting model accuracy:', accuracy)\n\n    cm_rf = confusion_matrix(y_test, y_pred)\n\n    ax = plt.subplot()\n    sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels') \n    ax.set_title('Voting classifier Confusion Matrix') \n    labels = [0, 1]\n    ax.xaxis.set_ticklabels(labels) \n    ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return vot_Model, accuracy\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:44.760574Z","iopub.execute_input":"2021-11-10T16:31:44.761271Z","iopub.status.idle":"2021-11-10T16:31:44.770421Z","shell.execute_reply.started":"2021-11-10T16:31:44.761233Z","shell.execute_reply":"2021-11-10T16:31:44.76991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAdaBoostClassifierModeldt(X_train, X_test, y_train, y_test):\n    setSeed()\n    abc_param_grid = {\n         'n_estimators': [10,20,30],\n    }\n    \n    abc_estimator = AdaBoostClassifier(DecisionTreeClassifier(random_state=0, max_depth=1))\n    \n    adaBoost_model = GridSearchCV(abc_estimator, abc_param_grid, cv=3, scoring='accuracy')\n\n    # Train Adaboost Classifer\n    adaBoost_model = adaBoost_model.fit(X_train, y_train)\n    \n    print(\"Best Parameters:\\n\", adaBoost_model.best_params_)\n\n    #Predict the response for test dataset\n    y_pred = adaBoost_model.predict(X_test)\n\n    accuracy = round(accuracy_score(y_test, y_pred), 3)\n    print('AdaBoostClassifier model accuracy:', accuracy)\n    \n    cm_rf = confusion_matrix(y_test, y_pred)\n\n    ax = plt.subplot()\n    sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels') \n    ax.set_title('AdaBoost classifier Confusion Matrix') \n    labels = [0, 1]\n    ax.xaxis.set_ticklabels(labels) \n    ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return adaBoost_model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:47.569796Z","iopub.execute_input":"2021-11-10T16:31:47.570098Z","iopub.status.idle":"2021-11-10T16:31:47.57747Z","shell.execute_reply.started":"2021-11-10T16:31:47.570065Z","shell.execute_reply":"2021-11-10T16:31:47.576455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAdaBoostClassifierModelsv(X_train, X_test, y_train, y_test):\n    setSeed()\n    abc_param_grid = {\n         'n_estimators': [10, 20, 30],\n    }\n    \n    abc_estimator = AdaBoostClassifier(SVC(kernel='rbf',probability=True),n_estimators=15,  learning_rate=1.0, algorithm='SAMME.R')\n    \n    adaBoost_model = GridSearchCV(abc_estimator, abc_param_grid, cv=3, scoring='accuracy')\n\n    # Train Adaboost Classifer\n    adaBoost_model = adaBoost_model.fit(X_train, y_train)\n    \n    print(\"Best Parameters:\\n\", adaBoost_model.best_params_)\n\n    #Predict the response for test dataset\n    y_pred = adaBoost_model.predict(X_test)\n\n    accuracy = round(accuracy_score(y_test, y_pred), 3)\n    print('AdaBoostClassifier model accuracy:', accuracy)\n    \n    cm_rf = confusion_matrix(y_test, y_pred)\n\n    ax = plt.subplot()\n    sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels') \n    ax.set_title('AdaBoost classifier Confusion Matrix') \n    labels = [0, 1]\n    ax.xaxis.set_ticklabels(labels) \n    ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return adaBoost_model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:50.517601Z","iopub.execute_input":"2021-11-10T16:31:50.518438Z","iopub.status.idle":"2021-11-10T16:31:50.525422Z","shell.execute_reply.started":"2021-11-10T16:31:50.518394Z","shell.execute_reply":"2021-11-10T16:31:50.524833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAdaBoostClassifierModelrf(X_train, X_test, y_train, y_test):\n    setSeed()\n    abc_param_grid = {\n         'n_estimators': [10, 20, 30],\n    }\n    \n    abc_estimator = AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=0))\n    \n    adaBoost_model = GridSearchCV(abc_estimator, abc_param_grid, cv=3, scoring='accuracy')\n\n    # Train Adaboost Classifer\n    adaBoost_model = adaBoost_model.fit(X_train, y_train)\n    \n    print(\"Best Parameters:\\n\", adaBoost_model.best_params_)\n\n    #Predict the response for test dataset\n    y_pred = adaBoost_model.predict(X_test)\n\n    accuracy = round(accuracy_score(y_test, y_pred), 3)\n    print('AdaBoostClassifier model accuracy:', accuracy)\n    \n    cm_rf = confusion_matrix(y_test, y_pred)\n\n    ax = plt.subplot()\n    sns.heatmap(cm_rf, annot=True, ax = ax, fmt='g', cmap='Greens') \n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels') \n    ax.set_title('AdaBoost classifier Confusion Matrix') \n    labels = [0, 1]\n    ax.xaxis.set_ticklabels(labels) \n    ax.yaxis.set_ticklabels(labels, rotation=360);\n    \n    return adaBoost_model, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:31:53.47485Z","iopub.execute_input":"2021-11-10T16:31:53.475579Z","iopub.status.idle":"2021-11-10T16:31:53.483717Z","shell.execute_reply.started":"2021-11-10T16:31:53.475537Z","shell.execute_reply":"2021-11-10T16:31:53.483116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co1_model_5, _ = votingModel(X_ds1_train_pca, X_ds1_test_pca, co1_train, co1_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:32:02.48481Z","iopub.execute_input":"2021-11-10T16:32:02.48523Z","iopub.status.idle":"2021-11-10T16:32:23.999735Z","shell.execute_reply.started":"2021-11-10T16:32:02.485183Z","shell.execute_reply":"2021-11-10T16:32:23.999183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co1_ds1_pred = co1_model_5.predict(test_data_1_pca)\nco1_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:13:19.099494Z","iopub.execute_input":"2021-11-10T13:13:19.100346Z","iopub.status.idle":"2021-11-10T13:13:19.117867Z","shell.execute_reply.started":"2021-11-10T13:13:19.100293Z","shell.execute_reply":"2021-11-10T13:13:19.116896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co2_model_1, _ = getLogisticRegressionModel(X_ds1_train, X_ds1_test, co2_train, co2_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:32:30.964995Z","iopub.execute_input":"2021-11-10T16:32:30.965389Z","iopub.status.idle":"2021-11-10T16:32:52.203325Z","shell.execute_reply.started":"2021-11-10T16:32:30.965361Z","shell.execute_reply":"2021-11-10T16:32:52.2028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co2_ds1_pred = co2_model_1.predict(test_data_1)\nco2_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:13:51.061582Z","iopub.execute_input":"2021-11-10T13:13:51.062213Z","iopub.status.idle":"2021-11-10T13:13:51.334037Z","shell.execute_reply.started":"2021-11-10T13:13:51.062171Z","shell.execute_reply":"2021-11-10T13:13:51.333141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co3_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:13:53.729186Z","iopub.execute_input":"2021-11-10T13:13:53.729483Z","iopub.status.idle":"2021-11-10T13:13:53.737526Z","shell.execute_reply.started":"2021-11-10T13:13:53.729451Z","shell.execute_reply":"2021-11-10T13:13:53.736374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co4_model_2, _ = getLogisticRegressionModel(X_ds2_train_pca, X_ds2_test_pca, co4_train, co4_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:14:00.989674Z","iopub.execute_input":"2021-11-10T13:14:00.990172Z","iopub.status.idle":"2021-11-10T13:14:01.982903Z","shell.execute_reply.started":"2021-11-10T13:14:00.990137Z","shell.execute_reply":"2021-11-10T13:14:01.982386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co4_ds1_pred = co4_model_2.predict(test_data_2_pca)\nco4_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:14:12.302283Z","iopub.execute_input":"2021-11-10T13:14:12.30281Z","iopub.status.idle":"2021-11-10T13:14:12.315614Z","shell.execute_reply.started":"2021-11-10T13:14:12.302775Z","shell.execute_reply":"2021-11-10T13:14:12.314718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co5_model_1, _ = getLogisticRegressionModel(X_ds2_train, X_ds2_test, co5_train, co5_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:33:00.797446Z","iopub.execute_input":"2021-11-10T16:33:00.79784Z","iopub.status.idle":"2021-11-10T16:34:57.220507Z","shell.execute_reply.started":"2021-11-10T16:33:00.797812Z","shell.execute_reply":"2021-11-10T16:34:57.219707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co5_ds1_pred = co5_model_1.predict(test_data_2)\nco5_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:23:26.701774Z","iopub.execute_input":"2021-11-10T13:23:26.702279Z","iopub.status.idle":"2021-11-10T13:23:27.798953Z","shell.execute_reply.started":"2021-11-10T13:23:26.702235Z","shell.execute_reply":"2021-11-10T13:23:27.798154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co6_model_6, _ = getAdaBoostClassifierModeldt(X_ds2_train, X_ds2_test, co6_train, co6_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:36:52.900003Z","iopub.execute_input":"2021-11-10T16:36:52.900259Z","iopub.status.idle":"2021-11-10T16:42:55.121887Z","shell.execute_reply.started":"2021-11-10T16:36:52.900233Z","shell.execute_reply":"2021-11-10T16:42:55.121047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co6_ds1_pred = co6_model_6.predict(test_data_2)\nco6_ds1_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:32:30.863044Z","iopub.execute_input":"2021-11-10T13:32:30.863365Z","iopub.status.idle":"2021-11-10T13:32:40.111212Z","shell.execute_reply.started":"2021-11-10T13:32:30.86333Z","shell.execute_reply":"2021-11-10T13:32:40.110641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nwith open('/kaggle/working/predictions.csv', 'w') as f:\n    f.write('Id,Predicted\\n')\n    \n    # write co1\n    for co1 in co1_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co1)))\n        i = i + 1\n        \n    # write co2\n    for co2 in co2_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co2)))\n        i = i + 1\n        \n    # write co3\n    for co3 in co3_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co3)))\n        i = i + 1\n        \n    # write co4\n    for co4 in co4_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co4)))\n        i = i + 1\n    \n    # write co5\n    for co5 in co5_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co5)))\n        i = i + 1\n    \n    # write co6\n    for co6 in co6_ds1_pred:\n        f.write('{},{}\\n'.format(i, int(co6)))\n        i = i + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-10T13:33:37.460249Z","iopub.execute_input":"2021-11-10T13:33:37.460613Z","iopub.status.idle":"2021-11-10T13:33:37.472616Z","shell.execute_reply.started":"2021-11-10T13:33:37.460576Z","shell.execute_reply":"2021-11-10T13:33:37.471925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}